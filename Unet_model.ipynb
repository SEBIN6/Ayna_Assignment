{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPudRnHwqjg0o/M2O9820YH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEBIN6/Ayna_Assignment/blob/main/Unet_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNZIPPING DATA"
      ],
      "metadata": {
        "id": "YRHXxP0Y96Tv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zfGKBzcq6G7g"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "!unzip -q dataset.zip -d dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --quiet\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import wandb\n"
      ],
      "metadata": {
        "id": "O-t3j6Wo6Pol"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET CLASS"
      ],
      "metadata": {
        "id": "cqLntln26T0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class PolygonColorDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.input_dir = os.path.join(root_dir, \"inputs\")\n",
        "        self.output_dir = os.path.join(root_dir, \"outputs\")\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(os.path.join(root_dir, \"data.json\")) as f:\n",
        "            self.data = json.load(f)\n",
        "\n",
        "\n",
        "        self.color_map = {\n",
        "            \"red\": [1, 0, 0],\n",
        "            \"green\": [0, 1, 0],\n",
        "            \"blue\": [0, 0, 1],\n",
        "            \"yellow\": [1, 1, 0],\n",
        "            \"cyan\": [0, 1, 1],\n",
        "            \"magenta\": [1, 0, 1],\n",
        "            \"black\": [0, 0, 0],\n",
        "            \"white\": [1, 1, 1],\n",
        "            \"orange\": [1, 0.5, 0],       #\n",
        "            \"purple\": [0.5, 0, 0.5],\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        input_name = item.get(\"input_polygon\") or item.get(\"input\") or item.get(\"input_file\")\n",
        "        output_name = item.get(\"output_image\") or item.get(\"output\") or item.get(\"output_file\")\n",
        "        color_name = item.get(\"colour\") or item.get(\"color\")\n",
        "\n",
        "        if input_name is None or output_name is None or color_name is None:\n",
        "            raise KeyError(f\"Missing expected keys in data item: {item}\")\n",
        "\n",
        "        input_path = os.path.join(self.input_dir, input_name)\n",
        "        output_path = os.path.join(self.output_dir, output_name)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            raise FileNotFoundError(f\"Input image not found: {input_path}\")\n",
        "        if not os.path.exists(output_path):\n",
        "            raise FileNotFoundError(f\"Output image not found: {output_path}\")\n",
        "\n",
        "        input_img = Image.open(input_path).convert(\"L\")  # grayscale\n",
        "        output_img = Image.open(output_path).convert(\"RGB\")  # target colored\n",
        "\n",
        "        if self.transform:\n",
        "            input_img = self.transform(input_img)\n",
        "            output_img = self.transform(output_img)\n",
        "        else:\n",
        "\n",
        "            import torchvision.transforms as T\n",
        "            to_tensor = T.ToTensor()\n",
        "            input_img = to_tensor(input_img)\n",
        "            output_img = to_tensor(output_img)\n",
        "\n",
        "        # color vector (lowercase)\n",
        "        color_key = color_name.lower()\n",
        "        if color_key not in self.color_map:\n",
        "            # fallback: try approximate or default to black\n",
        "            print(f\"Warning: color '{color_name}' not in map, defaulting to black\")\n",
        "            color_vec = torch.tensor(self.color_map[\"black\"], dtype=torch.float32)\n",
        "        else:\n",
        "            color_vec = torch.tensor(self.color_map[color_key], dtype=torch.float32)\n",
        "\n",
        "        return input_img, color_vec, output_img\n"
      ],
      "metadata": {
        "id": "8A6aSObD6Xqp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UNET"
      ],
      "metadata": {
        "id": "SWKyHajV6bSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, input_channels=4, output_channels=3):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.enc1 = conv_block(4, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec1 = conv_block(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec2 = conv_block(128, 64)\n",
        "\n",
        "        self.final = nn.Conv2d(64, output_channels, 1)\n",
        "\n",
        "    def forward(self, x, color):\n",
        "        B, _, H, W = x.shape\n",
        "        color_map = color.view(B, 3, 1, 1).expand(B, 3, H, W)\n",
        "        x = torch.cat([x, color_map], dim=1)\n",
        "\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "\n",
        "        d1 = self.up1(e3)\n",
        "        d1 = torch.cat([d1, e2], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = torch.cat([d2, e1], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        return self.final(d2)\n"
      ],
      "metadata": {
        "id": "QubbuqVQ6dT8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING SCRIPT"
      ],
      "metadata": {
        "id": "8F2egNjh-QLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"ayna-polygon-coloring\", name=\"unet-training\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((128, 128)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "train_ds = PolygonColorDataset(\"dataset/dataset/training\", transform)\n",
        "val_ds = PolygonColorDataset(\"dataset/dataset/validation\", transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=16)\n",
        "\n",
        "model = UNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for x, c, y in tqdm(train_loader):\n",
        "        x, c, y = x.to(device), c.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x, c)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    wandb.log({\"epoch\": epoch, \"train_loss\": train_loss / len(train_loader)})\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x, c, y in val_loader:\n",
        "            x, c, y = x.to(device), c.to(device), y.to(device)\n",
        "            y_pred = model(x, c)\n",
        "            loss = criterion(y_pred, y)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        wandb.log({\"epoch\": epoch, \"val_loss\": val_loss / len(val_loader)})\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), \"unet_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "_g9WMNCj6iZ-",
        "outputId": "ddc9aa58-fc46-403d-d9aa-165957089012"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msebin2308\u001b[0m (\u001b[33msebin2308-mbccet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250804_071009-lszf1isu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring/runs/lszf1isu' target=\"_blank\">unet-training</a></strong> to <a href='https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring' target=\"_blank\">https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring/runs/lszf1isu' target=\"_blank\">https://wandb.ai/sebin2308-mbccet/ayna-polygon-coloring/runs/lszf1isu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:53<00:00, 13.45s/it]\n",
            "100%|██████████| 4/4 [00:51<00:00, 12.85s/it]\n",
            "100%|██████████| 4/4 [00:50<00:00, 12.56s/it]\n",
            "100%|██████████| 4/4 [00:50<00:00, 12.69s/it]\n",
            "100%|██████████| 4/4 [00:51<00:00, 12.88s/it]\n",
            "100%|██████████| 4/4 [00:54<00:00, 13.74s/it]\n",
            "100%|██████████| 4/4 [00:55<00:00, 13.93s/it]\n",
            "100%|██████████| 4/4 [00:53<00:00, 13.30s/it]\n",
            "100%|██████████| 4/4 [00:52<00:00, 13.15s/it]\n",
            "100%|██████████| 4/4 [00:51<00:00, 12.79s/it]\n"
          ]
        }
      ]
    }
  ]
}